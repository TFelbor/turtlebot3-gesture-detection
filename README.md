# TurtleBot3 Hand Gesture Recognition System (v1.0)

**Project Status:** Completed (Semester 1 Deliverable)  
**Timeline:** September 2025 - December 2025

---

## üìñ Executive Summary
This project implements a "Remote Control without a Remote" for the TurtleBot3 robot. By leveraging computer vision and distributed robotics, we created a system that allows users to drive a mobile robot using intuitive hand gestures (e.g., a fist to drive forward, a thumb to turn left). 

The system was built using **ROS Noetic** and **MediaPipe**, achieving real-time responsiveness with under 500ms latency.

[[Placeholder: Insert GIF or Screenshot of Robot Moving Here]](https://github.com/user-attachments/assets/b3628aa3-530c-42d3-add7-b791bc518206)

<img width="1342" height="1024" alt="forward_tb3" src="https://github.com/user-attachments/assets/e321f4cb-2d22-442a-9720-85a99278f174" />

*Figure 1: Real-time hand tracking and gesture classification of closed palm running on the workstation.*

<img width="1342" height="1024" alt="right_tb3" src="https://github.com/user-attachments/assets/ac081369-1286-43df-844c-3ad7428bece9" />

*Figure 2: Real-time hand tracking and gesture classification of closed palm & thumb poiting right palm running on the workstation.*


<img width="1342" height="1024" alt="left_tb3" src="https://github.com/user-attachments/assets/a481bbed-79a4-4073-8eba-cbb5638f4c4c" />

*Figure 3: Real-time hand tracking and gesture classification of closed palm & thumb pointing left running on the workstation.*


---

## ü§ñ System Architecture Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       UBUNTU VM (Development Machine)       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  Gesture Recognition Node (Python + MediaPipe)          ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Capture video from built in camera                   ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Detect hand poses using MediaPipe                    ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Map poses to gesture commands (GO, STOP, etc.)       ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Publish commands to ROS topic: /gesture_command      ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ              ‚Üì (ROS topic: /gesture_command)                ‚îÇ
‚îÇ         Over Network (WiFi/SSH)                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 RASPBERRY PI 4 (TurtleBot3)                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  Motion Control Node (Python + ROS)                     ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Subscribe to /gesture_command topic                  ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Translate commands to wheel velocities               ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Implement 3-second auto-STOP safety feature          ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Publish to /cmd_vel (motor control)                  ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ              ‚Üì (ROS topic: /cmd_vel)                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  TurtleBot3 Motor Drivers                               ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Actuate wheels based on velocity commands            ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Provide odometry feedback (optional)                 ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ              ‚Üì (Physical)                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  TurtleBot3 Chassis & Motors                            ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Execute movement commands                            ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üîÑ ROS Node Communication Graph

```
Gesture Recognition Node          Motion Control Node
    (Ubuntu VM)                      (Raspberry Pi)
        ‚îÇ                                  ‚îÇ
        ‚îÇ Publishes:                       ‚îÇ
        ‚îú‚îÄ‚Üí /gesture_command ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Subscribes
        ‚îÇ  (String: GO, STOP,              ‚îÇ
        ‚îÇ   LEFT, RIGHT, BACK-UP)          ‚îÇ
        ‚îÇ                                  ‚îÇ
        ‚îÇ                           Publishes:
        ‚îÇ                           ‚îÇ
        ‚îÇ                           ‚îú‚îÄ‚Üí /cmd_vel
        ‚îÇ                              (Twist message)
        ‚îÇ                              
        ‚îÇ                           Subscribes:
        ‚îÇ                           ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ /gesture_timeout
                                       (auto-STOP signal)
```
### State Machine Diagram
```
stateDiagram-v2
    [*] --> Idle
    
    state "Idle / Wait" as Idle {
        [*] --> NoHandDetected
    }

    state "Active Operation" as Active {
        Moving --> Moving : Hand Tracked
        Moving --> SafetyPause : Hand Lost
    }

    Idle --> Active : Hand Detected
    Active --> Idle : Safety Timeout (>3s)
    
    state SafetyPause {
        [*] --> TimerStart
        TimerStart --> TimerExpired : > 3 Seconds
        TimerStart --> Moving : Hand Regained
    }
    
    TimerExpired --> Idle : Trigger Auto-STOP
```
### ü§ô Supported Gestures
| Gesture | Action | Description |
| :--- | :--- | :--- |
| **Fist** | **FORWARD** | Robot drives straight at 0.2 m/s |
| **Open Palm** | **STOP** | Robot halts immediately |
| **Thumb Left** | **TURN LEFT** | Robot rotates counter-clockwise |
| **Thumb Right** | **TURN RIGHT** | Robot rotates clockwise |

---

## üõ†Ô∏è Installation & Setup

### ‚ö†Ô∏è Hardware Setup & Prerequisites
**Important:** This repository assumes your TurtleBot3 is already physically assembled, the OpenCR board is configured, and the Raspberry Pi is networked.

If you are setting up the robot for the first time, you **must** complete the steps in the official **[TurtleBot3 Quick Start Guide](https://emanual.robotis.com/docs/en/platform/turtlebot3/quick-start/)** first. This resource is helpful for:
* Assembling the hardware chassis.
* Flashing the Raspberry Pi with the correct ROS Noetic image.
* Configuring the OpenCR motor driver board.
* Setting up the basic network connection.

**System Requirements:**
* **Workstation:** Ubuntu 20.04 with Webcam (VM or Native)
* **Robot:** TurtleBot3 (Burger model) with Raspberry Pi 4
* **ROS Version:** Noetic
* **Network:** Both devices must be on the same WiFi network and be able to ping each other.

### 1. Workstation Setup (The "Brain")
```bash
# Clone the repository
git clone [https://github.com/](https://github.com/)TFelbor/turtlebot3-gesture-control.git

# Install dependencies
pip3 install mediapipe opencv-python

# Build workspace
cd turtlebot3-gesture-control
catkin_make
source devel/setup.bash
````

### 2. Robot Setup (The "Body")

*SSH into the Raspberry Pi and clone this repo into `~/catkin_ws/src`*

```bash
cd ~/catkin_ws/src
git clone [https://github.com/](https://github.com/)TFelbor/turtlebot3-gesture-control.git
cd ~/catkin_ws
catkin_make
source devel/setup.bash
```

---

## üöÄ How to Run

1.  **Start the Robot Hardware (Pi):**

    ```bash
    roslaunch turtlebot3_bringup turtlebot3_robot.launch
    ```

2.  **Start Motion Listener (Pi):**

    ```bash
    rosrun motion_control motion_control_node.py
    ```

3.  **Start Vision System (Workstation):**

    ```bash
    # Ensure this points to your Robot's current IP
    export ROS_MASTER_URI=http://[ROBOT_IP]:11311
    rosrun turtlebot3_gesture gesture_recognition_node.py
    ```
